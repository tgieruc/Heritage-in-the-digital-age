{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import src.GLIP.maskrcnn_benchmark as maskrcnn_benchmark\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.ops import nms\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.modules['maskrcnn_benchmark'] = maskrcnn_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>filename</th>\n",
       "      <th>caption</th>\n",
       "      <th>model</th>\n",
       "      <th>expr</th>\n",
       "      <th>conf</th>\n",
       "      <th>bbox</th>\n",
       "      <th>labels</th>\n",
       "      <th>image_id</th>\n",
       "      <th>caption_raw</th>\n",
       "      <th>caption_preprocessed</th>\n",
       "      <th>title_raw</th>\n",
       "      <th>title_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1027</td>\n",
       "      <td>JOMU_32980_2k_324w.jpg</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.8280), tensor(0.7924), tensor(0.6899...</td>\n",
       "      <td>[[tensor(178.8594), tensor(116.5122), tensor(2...</td>\n",
       "      <td>[people, people, people, people, people, peopl...</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "      <td>Saint Nicholas Festival Market, Place de Notre...</td>\n",
       "      <td>saint nicholas festival market, place de notre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>CAPO_02480_2k_324w.jpg</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.8242), tensor(0.5884), tensor(0.5781...</td>\n",
       "      <td>[[tensor(0.8775), tensor(131.9302), tensor(81....</td>\n",
       "      <td>[soldiers, a building, a building, a building]</td>\n",
       "      <td>516.0</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "      <td>[Mobilization at Perolles in August 1914]</td>\n",
       "      <td>[mobilization at perolles in august 1914]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>543</td>\n",
       "      <td>JATH_26232_2k_324w.jpg</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.7898), tensor(0.7305), tensor(0.6872...</td>\n",
       "      <td>[[tensor(97.0861), tensor(137.5495), tensor(14...</td>\n",
       "      <td>[soldiers, soldiers, a military vehicle, soldi...</td>\n",
       "      <td>950.0</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "      <td>Additional service for women, Barracks de la P...</td>\n",
       "      <td>additional service for women, barracks de la p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>430</td>\n",
       "      <td>JATH_10616_2k_324w.jpg</td>\n",
       "      <td>women walking down a street.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.6900), tensor(0.6777), tensor(0.6676...</td>\n",
       "      <td>[[tensor(125.4207), tensor(111.6184), tensor(1...</td>\n",
       "      <td>[women, women, women, a street, women]</td>\n",
       "      <td>836.0</td>\n",
       "      <td>women walking down a street.</td>\n",
       "      <td>women walking down a street.</td>\n",
       "      <td>Procession on the route to the Alps during a w...</td>\n",
       "      <td>procession on the route to the alps during a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408</td>\n",
       "      <td>HAWI_01023_2k_324w.jpg</td>\n",
       "      <td>a photograph of a large tropical cyclone.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.7263)]</td>\n",
       "      <td>[[tensor(4.5861), tensor(13.1419), tensor(318....</td>\n",
       "      <td>[a large tropical cyclone]</td>\n",
       "      <td>814.0</td>\n",
       "      <td>a photograph of a large tropical cyclone.</td>\n",
       "      <td>a a large tropical cyclone.</td>\n",
       "      <td>Tornado over Lake Morat</td>\n",
       "      <td>tornado over lake morat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                filename  \\\n",
       "0  1027  JOMU_32980_2k_324w.jpg   \n",
       "1   183  CAPO_02480_2k_324w.jpg   \n",
       "2   543  JATH_26232_2k_324w.jpg   \n",
       "3   430  JATH_10616_2k_324w.jpg   \n",
       "4   408  HAWI_01023_2k_324w.jpg   \n",
       "\n",
       "                                             caption model     expr  \\\n",
       "0                people buying sweets at the market.  GLIP  caption   \n",
       "1  a group of soldiers stand in front of a building.  GLIP  caption   \n",
       "2     soldiers stand in front of a military vehicle.  GLIP  caption   \n",
       "3                       women walking down a street.  GLIP  caption   \n",
       "4          a photograph of a large tropical cyclone.  GLIP  caption   \n",
       "\n",
       "                                                conf  \\\n",
       "0  [tensor(0.8280), tensor(0.7924), tensor(0.6899...   \n",
       "1  [tensor(0.8242), tensor(0.5884), tensor(0.5781...   \n",
       "2  [tensor(0.7898), tensor(0.7305), tensor(0.6872...   \n",
       "3  [tensor(0.6900), tensor(0.6777), tensor(0.6676...   \n",
       "4                                   [tensor(0.7263)]   \n",
       "\n",
       "                                                bbox  \\\n",
       "0  [[tensor(178.8594), tensor(116.5122), tensor(2...   \n",
       "1  [[tensor(0.8775), tensor(131.9302), tensor(81....   \n",
       "2  [[tensor(97.0861), tensor(137.5495), tensor(14...   \n",
       "3  [[tensor(125.4207), tensor(111.6184), tensor(1...   \n",
       "4  [[tensor(4.5861), tensor(13.1419), tensor(318....   \n",
       "\n",
       "                                              labels  image_id  \\\n",
       "0  [people, people, people, people, people, peopl...    1488.0   \n",
       "1     [soldiers, a building, a building, a building]     516.0   \n",
       "2  [soldiers, soldiers, a military vehicle, soldi...     950.0   \n",
       "3             [women, women, women, a street, women]     836.0   \n",
       "4                         [a large tropical cyclone]     814.0   \n",
       "\n",
       "                                         caption_raw  \\\n",
       "0                people buying sweets at the market.   \n",
       "1  a group of soldiers stand in front of a building.   \n",
       "2     soldiers stand in front of a military vehicle.   \n",
       "3                       women walking down a street.   \n",
       "4          a photograph of a large tropical cyclone.   \n",
       "\n",
       "                                caption_preprocessed  \\\n",
       "0                people buying sweets at the market.   \n",
       "1  a group of soldiers stand in front of a building.   \n",
       "2     soldiers stand in front of a military vehicle.   \n",
       "3                       women walking down a street.   \n",
       "4                        a a large tropical cyclone.   \n",
       "\n",
       "                                           title_raw  \\\n",
       "0  Saint Nicholas Festival Market, Place de Notre...   \n",
       "1          [Mobilization at Perolles in August 1914]   \n",
       "2  Additional service for women, Barracks de la P...   \n",
       "3  Procession on the route to the Alps during a w...   \n",
       "4                            Tornado over Lake Morat   \n",
       "\n",
       "                                  title_preprocessed  \n",
       "0  saint nicholas festival market, place de notre...  \n",
       "1          [mobilization at perolles in august 1914]  \n",
       "2  additional service for women, barracks de la p...  \n",
       "3  procession on the route to the alps during a w...  \n",
       "4                            tornado over lake morat  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pickle.load(open('../data/dataset_for_segmentation.p','rb'))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle_dir = '../data/phrase_grounding_results/'\n",
    "MDETR_caption = pickle.load(open(pickle_dir + 'MDETR_full_caption.p', 'rb'))\n",
    "MDETR_title = pickle.load(open(pickle_dir + 'MDETR_full_title.p', 'rb'))\n",
    "GLIP_caption = pickle.load(open(pickle_dir + 'GLIP_full_caption.p', 'rb'))\n",
    "GLIP_title = pickle.load(open(pickle_dir + 'GLIP_full_title.p', 'rb'))\n",
    "dataset_dict = pickle.load(open('../data/dataset_for_phrase_grounding/dataset.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GLIP2MDETR(glip_array):\n",
    "    mdetr_array = []\n",
    "    for elem in glip_array:\n",
    "        caption = [elem[1][k -1] if k < len(elem[1]) else elem[1][len(elem[1]) - 1] for k in elem[0].get_field('labels')]\n",
    "        mdetr_array.append([elem[0].get_field('scores'), elem[0].bbox, caption])\n",
    "    return mdetr_array\n",
    "GLIP_caption = GLIP2MDETR(GLIP_caption)\n",
    "GLIP_title = GLIP2MDETR(GLIP_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_nms(segmentation_array):\n",
    "    segmentation_array_ = []\n",
    "    for i, elem in enumerate(segmentation_array):\n",
    "        segmentation_array_.append(list(elem))\n",
    "    seg_filtered = copy.deepcopy(segmentation_array_)\n",
    "    for index_, elem in enumerate(segmentation_array_):\n",
    "        unique_caption = set(elem[2])\n",
    "        if len(elem[2]) != 0:\n",
    "            boolean_index = [[elem_ == cap for elem_ in elem[2]] for cap in list(unique_caption)]\n",
    "            idx = [[i for i, x in enumerate(bool_idx) if x] for bool_idx in boolean_index]\n",
    "            idx_to_keep = [nms(boxes=torch.index_select(elem[1], 0, torch.tensor(idx_)),\n",
    "                               scores=torch.index_select(elem[0], 0, torch.tensor(idx_)), iou_threshold=0.2) for idx_ in\n",
    "                           idx]\n",
    "            scores = []\n",
    "            boxes = []\n",
    "            captions = []\n",
    "            for idx_, idx_tokeep, caption in zip(idx, idx_to_keep, list(unique_caption)):\n",
    "                scores += (elem[0][idx_][idx_tokeep])\n",
    "                boxes += (elem[1][idx_][idx_tokeep])\n",
    "                captions += (\n",
    "                    [elem[2][i].removeprefix(' ') for i in torch.index_select(torch.tensor(idx_), 0, idx_tokeep)])\n",
    "\n",
    "            seg_filtered[index_][0] = torch.stack(scores, dim=0)\n",
    "            seg_filtered[index_][1] = torch.stack(boxes, dim=0)\n",
    "            seg_filtered[index_][2] = captions\n",
    "\n",
    "    return seg_filtered\n",
    "\n",
    "\n",
    "def global_det_nms(segmentation_array):\n",
    "    segmentation_array_ = []\n",
    "    for i, elem in enumerate(segmentation_array):\n",
    "        segmentation_array_.append(list(elem))\n",
    "    seg_filtered = copy.deepcopy(segmentation_array_)\n",
    "    for index_, elem in enumerate(segmentation_array_):\n",
    "        if len(elem[2]) != 0:\n",
    "            idx_to_keep = nms(boxes=elem[1], scores=elem[0], iou_threshold=0.9)\n",
    "            scores = []\n",
    "            boxes = []\n",
    "            captions = []\n",
    "            scores += (elem[0][idx_to_keep])\n",
    "            boxes += (elem[1][idx_to_keep])\n",
    "            captions += ([elem[2][i].removeprefix(' ') for i in idx_to_keep])\n",
    "\n",
    "            seg_filtered[index_][0] = torch.stack(scores, dim=0)\n",
    "            seg_filtered[index_][1] = torch.stack(boxes, dim=0)\n",
    "            seg_filtered[index_][2] = captions\n",
    "\n",
    "    return seg_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDETR_caption = global_det_nms(det_nms(MDETR_caption))\n",
    "MDETR_title = global_det_nms(det_nms(MDETR_title))\n",
    "GLIP_caption = global_det_nms(det_nms(GLIP_caption))\n",
    "GLIP_title = global_det_nms(det_nms(GLIP_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conf</th>\n",
       "      <th>bbox</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[tensor(0.9756), tensor(0.9001), tensor(0.8900)]</td>\n",
       "      <td>[[tensor(65.0094), tensor(1.1163), tensor(324....</td>\n",
       "      <td>[the wall of father girard, inauguration plaqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[tensor(0.9990)]</td>\n",
       "      <td>[[tensor(81.8896), tensor(160.1014), tensor(22...</td>\n",
       "      <td>[patient of dr xavier cuony city]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tensor(0.9510)]</td>\n",
       "      <td>[[tensor(86.9352), tensor(87.6198), tensor(244...</td>\n",
       "      <td>[felsenegg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[tensor(0.9978), tensor(0.9940)]</td>\n",
       "      <td>[[tensor(39.9502), tensor(162.3252), tensor(27...</td>\n",
       "      <td>[his bike, male ( hermann nussbaumer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tensor(0.9960), tensor(0.9914), tensor(0.9859...</td>\n",
       "      <td>[[tensor(141.7642), tensor(84.6272), tensor(27...</td>\n",
       "      <td>[two women one, two women one, regional costum...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                conf  \\\n",
       "0   [tensor(0.9756), tensor(0.9001), tensor(0.8900)]   \n",
       "1                                   [tensor(0.9990)]   \n",
       "2                                   [tensor(0.9510)]   \n",
       "3                   [tensor(0.9978), tensor(0.9940)]   \n",
       "4  [tensor(0.9960), tensor(0.9914), tensor(0.9859...   \n",
       "\n",
       "                                                bbox  \\\n",
       "0  [[tensor(65.0094), tensor(1.1163), tensor(324....   \n",
       "1  [[tensor(81.8896), tensor(160.1014), tensor(22...   \n",
       "2  [[tensor(86.9352), tensor(87.6198), tensor(244...   \n",
       "3  [[tensor(39.9502), tensor(162.3252), tensor(27...   \n",
       "4  [[tensor(141.7642), tensor(84.6272), tensor(27...   \n",
       "\n",
       "                                                expr  \n",
       "0  [the wall of father girard, inauguration plaqu...  \n",
       "1                  [patient of dr xavier cuony city]  \n",
       "2                                        [felsenegg]  \n",
       "3              [his bike, male ( hermann nussbaumer]  \n",
       "4  [two women one, two women one, regional costum...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MDETR_title = pd.DataFrame(MDETR_title).rename({0:'conf', 1:'bbox', 2:'expr'}, axis=1)\n",
    "MDETR_caption = pd.DataFrame(MDETR_caption).rename({0:'conf', 1:'bbox', 2:'expr'}, axis=1)\n",
    "GLIP_caption = pd.DataFrame(GLIP_caption).rename({0:'conf', 1:'bbox', 2:'expr'}, axis=1)\n",
    "GLIP_title = pd.DataFrame(GLIP_title).rename({0:'conf', 1:'bbox', 2:'expr'}, axis=1)\n",
    "MDETR_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each element in the dataset, we want to filter results that have confidence < 0.75\n",
    "# import compress\n",
    "from itertools import compress\n",
    "\n",
    "def filter_results(elem):\n",
    "    conf = elem['conf']\n",
    "    bbox = elem['bbox']\n",
    "    expr = elem['expr']\n",
    "    keep = conf > 0.75\n",
    "    conf = conf[keep]\n",
    "    bbox = bbox[keep]\n",
    "    expr = list(compress(expr, keep))\n",
    "\n",
    "    return {'conf': conf, 'bbox': bbox, 'expr': expr}\n",
    "\n",
    "def filter_results_df(df):\n",
    "    new_df = df.copy()\n",
    "    df = df.apply(filter_results, axis=1)\n",
    "    new_df['conf'] = df.apply(lambda x: x['conf'])\n",
    "    new_df['bbox'] = df.apply(lambda x: x['bbox'])\n",
    "    new_df['expr'] = df.apply(lambda x: x['expr'])\n",
    "    return new_df\n",
    "\n",
    "MDETR_title = filter_results_df(MDETR_title)\n",
    "MDETR_caption = filter_results_df(MDETR_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_min_bbox(bbox):\n",
    "    try:\n",
    "        return int((bbox[:,2:] - bbox[:,:2]).prod(axis=1).min())\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_max_bbox(bbox):\n",
    "    try:\n",
    "        return int((bbox[:,2:] - bbox[:,:2]).prod(axis=1).max())\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_median_bbox(bbox):\n",
    "    try:\n",
    "        return int((bbox[:,2:] - bbox[:,:2]).prod(axis=1).median())\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "MDETR_title['num_bbox'] = MDETR_title.conf.apply(lambda x: len(x))\n",
    "MDETR_caption['num_bbox'] = MDETR_caption.conf.apply(lambda x: len(x))\n",
    "GLIP_caption['num_bbox'] = GLIP_caption.conf.apply(lambda x: len(x))\n",
    "GLIP_title['num_bbox'] = GLIP_title.conf.apply(lambda x: len(x))\n",
    "\n",
    "MDETR_title['min_bbox_area'] = MDETR_title.bbox.apply(lambda x: get_min_bbox(x))\n",
    "MDETR_caption['min_bbox_area'] = MDETR_caption.bbox.apply(lambda x: get_min_bbox(x))\n",
    "GLIP_caption['min_bbox_area'] = GLIP_caption.bbox.apply(lambda x: get_min_bbox(x))\n",
    "GLIP_title['min_bbox_area'] = GLIP_title.bbox.apply(lambda x: get_min_bbox(x))\n",
    "\n",
    "MDETR_title['max_bbox_area'] = MDETR_title.bbox.apply(lambda x: get_max_bbox(x))\n",
    "MDETR_caption['max_bbox_area'] = MDETR_caption.bbox.apply(lambda x: get_max_bbox(x))\n",
    "GLIP_caption['max_bbox_area'] = GLIP_caption.bbox.apply(lambda x: get_max_bbox(x))\n",
    "GLIP_title['max_bbox_area'] = GLIP_title.bbox.apply(lambda x: get_max_bbox(x))\n",
    "\n",
    "MDETR_title['median_bbox_area'] = MDETR_title.bbox.apply(lambda x: get_median_bbox(x))\n",
    "MDETR_caption['median_bbox_area'] = MDETR_caption.bbox.apply(lambda x: get_median_bbox(x))\n",
    "GLIP_caption['median_bbox_area'] = GLIP_caption.bbox.apply(lambda x: get_median_bbox(x))\n",
    "GLIP_title['median_bbox_area'] = GLIP_title.bbox.apply(lambda x: get_median_bbox(x))\n",
    "\n",
    "\n",
    "MDETR_title.drop(columns=['conf', 'bbox', 'expr'], inplace=True)\n",
    "MDETR_caption.drop(columns=['conf', 'bbox', 'expr'], inplace=True)\n",
    "GLIP_caption.drop(columns=['conf', 'bbox', 'expr'], inplace=True)\n",
    "GLIP_title.drop(columns=['conf', 'bbox', 'expr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_dict = pd.DataFrame(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_dict['len_caption'] = dataset_dict.caption.apply(lambda x: len(x['raw'].split()) if x['raw'] is not None else 0)\n",
    "dataset_dict['len_title'] = dataset_dict.title.apply(lambda x: len(x['raw'].split()) if x['raw'] is not None else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>len_caption</th>\n",
       "      <th>len_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ALCU_00005_2k_324w.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>ALCU_00033_2k_324w.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>ALNU_00015_2k_324w.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>ALNU_00016_2k_324w.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>ALNU_00052_2k_324w.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                filename  len_caption  len_title\n",
       "0         2  ALCU_00005_2k_324w.jpg            6         18\n",
       "1         4  ALCU_00033_2k_324w.jpg            5          8\n",
       "2         5  ALNU_00015_2k_324w.jpg            8          5\n",
       "3         6  ALNU_00016_2k_324w.jpg            7          6\n",
       "4         7  ALNU_00052_2k_324w.jpg            7          6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = dataset_dict.drop(columns=['title', 'caption'])\n",
    "dataset_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>len_caption</th>\n",
       "      <th>len_title</th>\n",
       "      <th>num_bbox_MDETR_title</th>\n",
       "      <th>min_bbox_area_MDETR_title</th>\n",
       "      <th>max_bbox_area_MDETR_title</th>\n",
       "      <th>median_bbox_area_MDETR_title</th>\n",
       "      <th>num_bbox_MDETR_caption</th>\n",
       "      <th>min_bbox_area_MDETR_caption</th>\n",
       "      <th>max_bbox_area_MDETR_caption</th>\n",
       "      <th>median_bbox_area_MDETR_caption</th>\n",
       "      <th>num_bbox_GLIP_caption</th>\n",
       "      <th>min_bbox_area_GLIP_caption</th>\n",
       "      <th>max_bbox_area_GLIP_caption</th>\n",
       "      <th>median_bbox_area_GLIP_caption</th>\n",
       "      <th>num_bbox_GLIP_title</th>\n",
       "      <th>min_bbox_area_GLIP_title</th>\n",
       "      <th>max_bbox_area_GLIP_title</th>\n",
       "      <th>median_bbox_area_GLIP_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>ALCU_00005_2k_324w.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>708.0</td>\n",
       "      <td>85733.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6862.0</td>\n",
       "      <td>50244.0</td>\n",
       "      <td>42928.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53361.0</td>\n",
       "      <td>53361.0</td>\n",
       "      <td>53361.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>2266.0</td>\n",
       "      <td>2266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>ALCU_00033_2k_324w.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>37941.0</td>\n",
       "      <td>37941.0</td>\n",
       "      <td>37941.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39104.0</td>\n",
       "      <td>146906.0</td>\n",
       "      <td>39104.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42747.0</td>\n",
       "      <td>42747.0</td>\n",
       "      <td>42747.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42669.0</td>\n",
       "      <td>42669.0</td>\n",
       "      <td>42669.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>ALNU_00015_2k_324w.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>52499.0</td>\n",
       "      <td>52499.0</td>\n",
       "      <td>52499.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50734.0</td>\n",
       "      <td>50734.0</td>\n",
       "      <td>50734.0</td>\n",
       "      <td>1</td>\n",
       "      <td>52736.0</td>\n",
       "      <td>52736.0</td>\n",
       "      <td>52736.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53524.0</td>\n",
       "      <td>53524.0</td>\n",
       "      <td>53524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>ALNU_00016_2k_324w.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>44221.0</td>\n",
       "      <td>62845.0</td>\n",
       "      <td>44221.0</td>\n",
       "      <td>2</td>\n",
       "      <td>41603.0</td>\n",
       "      <td>62280.0</td>\n",
       "      <td>41603.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42702.0</td>\n",
       "      <td>42702.0</td>\n",
       "      <td>42702.0</td>\n",
       "      <td>2</td>\n",
       "      <td>41893.0</td>\n",
       "      <td>67260.0</td>\n",
       "      <td>41893.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>ALNU_00052_2k_324w.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>26689.0</td>\n",
       "      <td>67220.0</td>\n",
       "      <td>33665.0</td>\n",
       "      <td>2</td>\n",
       "      <td>68115.0</td>\n",
       "      <td>113862.0</td>\n",
       "      <td>68115.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32610.0</td>\n",
       "      <td>117776.0</td>\n",
       "      <td>39382.0</td>\n",
       "      <td>3</td>\n",
       "      <td>33316.0</td>\n",
       "      <td>66190.0</td>\n",
       "      <td>39599.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                filename  len_caption  len_title  \\\n",
       "0         2  ALCU_00005_2k_324w.jpg            6         18   \n",
       "1         4  ALCU_00033_2k_324w.jpg            5          8   \n",
       "2         5  ALNU_00015_2k_324w.jpg            8          5   \n",
       "3         6  ALNU_00016_2k_324w.jpg            7          6   \n",
       "4         7  ALNU_00052_2k_324w.jpg            7          6   \n",
       "\n",
       "   num_bbox_MDETR_title  min_bbox_area_MDETR_title  max_bbox_area_MDETR_title  \\\n",
       "0                     3                      708.0                    85733.0   \n",
       "1                     1                    37941.0                    37941.0   \n",
       "2                     1                    52499.0                    52499.0   \n",
       "3                     2                    44221.0                    62845.0   \n",
       "4                     5                    26689.0                    67220.0   \n",
       "\n",
       "   median_bbox_area_MDETR_title  num_bbox_MDETR_caption  \\\n",
       "0                        1182.0                       3   \n",
       "1                       37941.0                       2   \n",
       "2                       52499.0                       1   \n",
       "3                       44221.0                       2   \n",
       "4                       33665.0                       2   \n",
       "\n",
       "   min_bbox_area_MDETR_caption  max_bbox_area_MDETR_caption  \\\n",
       "0                       6862.0                      50244.0   \n",
       "1                      39104.0                     146906.0   \n",
       "2                      50734.0                      50734.0   \n",
       "3                      41603.0                      62280.0   \n",
       "4                      68115.0                     113862.0   \n",
       "\n",
       "   median_bbox_area_MDETR_caption  num_bbox_GLIP_caption  \\\n",
       "0                         42928.0                      1   \n",
       "1                         39104.0                      1   \n",
       "2                         50734.0                      1   \n",
       "3                         41603.0                      1   \n",
       "4                         68115.0                      3   \n",
       "\n",
       "   min_bbox_area_GLIP_caption  max_bbox_area_GLIP_caption  \\\n",
       "0                     53361.0                     53361.0   \n",
       "1                     42747.0                     42747.0   \n",
       "2                     52736.0                     52736.0   \n",
       "3                     42702.0                     42702.0   \n",
       "4                     32610.0                    117776.0   \n",
       "\n",
       "   median_bbox_area_GLIP_caption  num_bbox_GLIP_title  \\\n",
       "0                        53361.0                    1   \n",
       "1                        42747.0                    1   \n",
       "2                        52736.0                    1   \n",
       "3                        42702.0                    2   \n",
       "4                        39382.0                    3   \n",
       "\n",
       "   min_bbox_area_GLIP_title  max_bbox_area_GLIP_title  \\\n",
       "0                    2266.0                    2266.0   \n",
       "1                   42669.0                   42669.0   \n",
       "2                   53524.0                   53524.0   \n",
       "3                   41893.0                   67260.0   \n",
       "4                   33316.0                   66190.0   \n",
       "\n",
       "   median_bbox_area_GLIP_title  \n",
       "0                       2266.0  \n",
       "1                      42669.0  \n",
       "2                      53524.0  \n",
       "3                      41893.0  \n",
       "4                      39599.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = pd.merge(dataset_dict, MDETR_title, left_index=True, right_index=True).rename({'num_bbox': 'num_bbox_MDETR_title', 'min_bbox_area': 'min_bbox_area_MDETR_title', 'max_bbox_area': 'max_bbox_area_MDETR_title', 'median_bbox_area': 'median_bbox_area_MDETR_title'}, axis=1)\n",
    "dataset_dict = pd.merge(dataset_dict, MDETR_caption, left_index=True, right_index=True).rename({'num_bbox': 'num_bbox_MDETR_caption', 'min_bbox_area': 'min_bbox_area_MDETR_caption', 'max_bbox_area': 'max_bbox_area_MDETR_caption', 'median_bbox_area': 'median_bbox_area_MDETR_caption'}, axis=1)\n",
    "dataset_dict = pd.merge(dataset_dict, GLIP_caption, left_index=True, right_index=True).rename({'num_bbox': 'num_bbox_GLIP_caption', 'min_bbox_area': 'min_bbox_area_GLIP_caption', 'max_bbox_area': 'max_bbox_area_GLIP_caption', 'median_bbox_area': 'median_bbox_area_GLIP_caption'}, axis=1)\n",
    "dataset_dict = pd.merge(dataset_dict, GLIP_title, left_index=True, right_index=True).rename({'num_bbox': 'num_bbox_GLIP_title', 'min_bbox_area': 'min_bbox_area_GLIP_title', 'max_bbox_area': 'max_bbox_area_GLIP_title', 'median_bbox_area': 'median_bbox_area_GLIP_title'}, axis=1)\n",
    "dataset_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>filename</th>\n",
       "      <th>caption</th>\n",
       "      <th>model</th>\n",
       "      <th>expr</th>\n",
       "      <th>conf</th>\n",
       "      <th>bbox</th>\n",
       "      <th>labels</th>\n",
       "      <th>image_id</th>\n",
       "      <th>caption_raw</th>\n",
       "      <th>caption_preprocessed</th>\n",
       "      <th>title_raw</th>\n",
       "      <th>title_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1027</td>\n",
       "      <td>JOMU_32980_2k_324w.jpg</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.8280), tensor(0.7924), tensor(0.6899...</td>\n",
       "      <td>[[tensor(178.8594), tensor(116.5122), tensor(2...</td>\n",
       "      <td>[people, people, people, people, people, peopl...</td>\n",
       "      <td>1488.0</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "      <td>Saint Nicholas Festival Market, Place de Notre...</td>\n",
       "      <td>saint nicholas festival market, place de notre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>183</td>\n",
       "      <td>CAPO_02480_2k_324w.jpg</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.8242), tensor(0.5884), tensor(0.5781...</td>\n",
       "      <td>[[tensor(0.8775), tensor(131.9302), tensor(81....</td>\n",
       "      <td>[soldiers, a building, a building, a building]</td>\n",
       "      <td>516.0</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "      <td>[Mobilization at Perolles in August 1914]</td>\n",
       "      <td>[mobilization at perolles in august 1914]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>543</td>\n",
       "      <td>JATH_26232_2k_324w.jpg</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.7898), tensor(0.7305), tensor(0.6872...</td>\n",
       "      <td>[[tensor(97.0861), tensor(137.5495), tensor(14...</td>\n",
       "      <td>[soldiers, soldiers, a military vehicle, soldi...</td>\n",
       "      <td>950.0</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "      <td>Additional service for women, Barracks de la P...</td>\n",
       "      <td>additional service for women, barracks de la p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>430</td>\n",
       "      <td>JATH_10616_2k_324w.jpg</td>\n",
       "      <td>women walking down a street.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.6900), tensor(0.6777), tensor(0.6676...</td>\n",
       "      <td>[[tensor(125.4207), tensor(111.6184), tensor(1...</td>\n",
       "      <td>[women, women, women, a street, women]</td>\n",
       "      <td>836.0</td>\n",
       "      <td>women walking down a street.</td>\n",
       "      <td>women walking down a street.</td>\n",
       "      <td>Procession on the route to the Alps during a w...</td>\n",
       "      <td>procession on the route to the alps during a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>408</td>\n",
       "      <td>HAWI_01023_2k_324w.jpg</td>\n",
       "      <td>a photograph of a large tropical cyclone.</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "      <td>[tensor(0.7263)]</td>\n",
       "      <td>[[tensor(4.5861), tensor(13.1419), tensor(318....</td>\n",
       "      <td>[a large tropical cyclone]</td>\n",
       "      <td>814.0</td>\n",
       "      <td>a photograph of a large tropical cyclone.</td>\n",
       "      <td>a a large tropical cyclone.</td>\n",
       "      <td>Tornado over Lake Morat</td>\n",
       "      <td>tornado over lake morat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx                filename  \\\n",
       "0  1027  JOMU_32980_2k_324w.jpg   \n",
       "1   183  CAPO_02480_2k_324w.jpg   \n",
       "2   543  JATH_26232_2k_324w.jpg   \n",
       "3   430  JATH_10616_2k_324w.jpg   \n",
       "4   408  HAWI_01023_2k_324w.jpg   \n",
       "\n",
       "                                             caption model     expr  \\\n",
       "0                people buying sweets at the market.  GLIP  caption   \n",
       "1  a group of soldiers stand in front of a building.  GLIP  caption   \n",
       "2     soldiers stand in front of a military vehicle.  GLIP  caption   \n",
       "3                       women walking down a street.  GLIP  caption   \n",
       "4          a photograph of a large tropical cyclone.  GLIP  caption   \n",
       "\n",
       "                                                conf  \\\n",
       "0  [tensor(0.8280), tensor(0.7924), tensor(0.6899...   \n",
       "1  [tensor(0.8242), tensor(0.5884), tensor(0.5781...   \n",
       "2  [tensor(0.7898), tensor(0.7305), tensor(0.6872...   \n",
       "3  [tensor(0.6900), tensor(0.6777), tensor(0.6676...   \n",
       "4                                   [tensor(0.7263)]   \n",
       "\n",
       "                                                bbox  \\\n",
       "0  [[tensor(178.8594), tensor(116.5122), tensor(2...   \n",
       "1  [[tensor(0.8775), tensor(131.9302), tensor(81....   \n",
       "2  [[tensor(97.0861), tensor(137.5495), tensor(14...   \n",
       "3  [[tensor(125.4207), tensor(111.6184), tensor(1...   \n",
       "4  [[tensor(4.5861), tensor(13.1419), tensor(318....   \n",
       "\n",
       "                                              labels  image_id  \\\n",
       "0  [people, people, people, people, people, peopl...    1488.0   \n",
       "1     [soldiers, a building, a building, a building]     516.0   \n",
       "2  [soldiers, soldiers, a military vehicle, soldi...     950.0   \n",
       "3             [women, women, women, a street, women]     836.0   \n",
       "4                         [a large tropical cyclone]     814.0   \n",
       "\n",
       "                                         caption_raw  \\\n",
       "0                people buying sweets at the market.   \n",
       "1  a group of soldiers stand in front of a building.   \n",
       "2     soldiers stand in front of a military vehicle.   \n",
       "3                       women walking down a street.   \n",
       "4          a photograph of a large tropical cyclone.   \n",
       "\n",
       "                                caption_preprocessed  \\\n",
       "0                people buying sweets at the market.   \n",
       "1  a group of soldiers stand in front of a building.   \n",
       "2     soldiers stand in front of a military vehicle.   \n",
       "3                       women walking down a street.   \n",
       "4                        a a large tropical cyclone.   \n",
       "\n",
       "                                           title_raw  \\\n",
       "0  Saint Nicholas Festival Market, Place de Notre...   \n",
       "1          [Mobilization at Perolles in August 1914]   \n",
       "2  Additional service for women, Barracks de la P...   \n",
       "3  Procession on the route to the Alps during a w...   \n",
       "4                            Tornado over Lake Morat   \n",
       "\n",
       "                                  title_preprocessed  \n",
       "0  saint nicholas festival market, place de notre...  \n",
       "1          [mobilization at perolles in august 1914]  \n",
       "2  additional service for women, barracks de la p...  \n",
       "3  procession on the route to the alps during a w...  \n",
       "4                            tornado over lake morat  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_dataset = pd.merge(dataset, dataset_dict.drop('image_id', axis=1), left_on='filename', right_on='filename', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((merged_dataset.model == 'GLIP') & (merged_dataset.expr==('caption'))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((merged_dataset.model == 'GLIP') & (merged_dataset.expr==('title'))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((merged_dataset.model == 'MDETR') & (merged_dataset.expr==('caption'))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((merged_dataset.model == 'MDETR') & (merged_dataset.expr==('title'))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "|         | MDETR | GLIP |\n",
    "|---------|-------|------|\n",
    "| Caption | 91    | 1130 |\n",
    "| Title   | 15    | 224  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5432/1317892172.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  merged_dataset['conf'] =  merged_dataset.conf.apply(lambda x: torch.tensor(x).numpy())\n",
      "/tmp/ipykernel_5432/1317892172.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  merged_dataset['bbox'] =  merged_dataset.bbox.apply(lambda x: torch.tensor(x).numpy())\n"
     ]
    }
   ],
   "source": [
    "merged_dataset['conf'] =  merged_dataset.conf.apply(lambda x: torch.tensor(x).numpy())\n",
    "merged_dataset['bbox'] =  merged_dataset.bbox.apply(lambda x: torch.tensor(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>model</th>\n",
       "      <th>expr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>2</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>2</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>2</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>MDETR</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>2</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>2</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>3</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>2</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>2</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>caption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3</td>\n",
       "      <td>GLIP</td>\n",
       "      <td>title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  model     expr\n",
       "1356      2   GLIP  caption\n",
       "1176      2   GLIP  caption\n",
       "1193      2   GLIP  caption\n",
       "375       0  MDETR  caption\n",
       "489       2   GLIP  caption\n",
       "904       2   GLIP  caption\n",
       "620       3   GLIP    title\n",
       "1205      2   GLIP  caption\n",
       "555       2   GLIP  caption\n",
       "214       3   GLIP    title"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_label(elem):\n",
    "    if elem['model'] == 'MDETR':\n",
    "        if elem['expr'] == 'caption':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        if elem['expr'] == 'caption':\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "merged_dataset['label'] = merged_dataset.apply(lambda x: get_label(x), axis=1)\n",
    "merged_dataset[['label', 'model', 'expr']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset.keys()\n",
    "features = merged_dataset.dropna()[[ 'len_caption', 'len_title',\n",
    "       'num_bbox_MDETR_title', 'min_bbox_area_MDETR_title',\n",
    "       'max_bbox_area_MDETR_title', 'median_bbox_area_MDETR_title',\n",
    "       'num_bbox_MDETR_caption', 'min_bbox_area_MDETR_caption',\n",
    "       'max_bbox_area_MDETR_caption', 'median_bbox_area_MDETR_caption',\n",
    "       'num_bbox_GLIP_caption', 'min_bbox_area_GLIP_caption',\n",
    "       'max_bbox_area_GLIP_caption', 'median_bbox_area_GLIP_caption',\n",
    "       'num_bbox_GLIP_title', 'min_bbox_area_GLIP_title',\n",
    "       'max_bbox_area_GLIP_title', 'median_bbox_area_GLIP_title']]\n",
    "labels = merged_dataset.dropna()[['label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [2],\n",
       "       ...,\n",
       "       [2],\n",
       "       [3],\n",
       "       [2]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.array(labels)\n",
    "labels_one_hot = np.eye(4)[labels].reshape(-1, 4)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels_one_hot, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (820, 18)\n",
      "Training Labels Shape: (820, 4)\n",
      "Testing Features Shape: (274, 18)\n",
      "Testing Labels Shape: (274, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7664233576642335\n"
     ]
    }
   ],
   "source": [
    "# get accuracy \n",
    "predictions = rf.predict(test_features)\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "gd = np.argmax(test_labels, axis=1)\n",
    "print('Accuracy:', (predictions == gd).sum()/ len(gd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2,\n",
       "       2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 0, 3,\n",
       "       2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 0, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 0, 3, 3, 3, 2, 2, 0, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1,\n",
       "       2, 3, 2, 2, 2, 0, 2, 2, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 3, 3, 2, 2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 3, 3, 2, 0, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3,\n",
       "       0, 2, 2, 2, 2, 2, 0, 3, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 0, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 0, 3, 2, 3, 1,\n",
       "       2, 2, 0, 3, 0, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 0, 2, 2, 2,\n",
       "       2, 2, 3, 2, 3, 3, 2, 3, 2, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.tensor(train_features).float()\n",
    "train_labels = torch.tensor(train_labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16366/2307519585.py:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_dataset = PyDataset(torch.tensor(train_features).float().cuda(), torch.tensor(train_labels).float().cuda())\n",
      "Epoch 1 - Loss: 0.4047330097087379: 100%|| 2/2 [00:00<00:00,  5.36it/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class PyDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, features, label):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - Number of data points we want to generate\n",
    "            seed - The seed to use to create the PRNG state with which we want to generate the data points\n",
    "            std - Standard deviation of the noise (see generate_continuous_xor function)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        # Number of data point we have. Alternatively self.data.shape[0], or self.label.shape[0]\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the idx-th data point of the dataset\n",
    "        # If we have multiple things to return (data point and label), we can return them as tuple\n",
    "        data_point = self.features[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label\n",
    "\n",
    "\n",
    "def train_NN(model, train_loader, optimizer, loss_fn, device, epochs=10):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        model - The model we want to train\n",
    "        train_loader - The data loader that will give us the data points\n",
    "        optimizer - The optimizer we want to use to update the model parameters\n",
    "        loss_fn - The loss function we want to use to compute the loss\n",
    "        device - The device on which we want to train the model\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    pbar = tqdm(range(epochs))\n",
    "    for epoch in pbar:\n",
    "        loss_array = []\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_array.append(loss.item())\n",
    "        pbar.set_description(f\"Epoch {epoch} - Loss: {np.mean(loss_array)}\")\n",
    "\n",
    "train_dataset = PyDataset(torch.tensor(train_features).float().cuda(), torch.tensor(train_labels).float().cuda())\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "classifier = nn.Sequential(\n",
    "    nn.Linear(18, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 4),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "classifier = classifier.cuda()\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.0001)\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "train_NN(classifier, train_data_loader, optimizer, loss, device='cuda', epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 41/274 (15%)\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "def eval_NN(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.argmax(dim=1, keepdim=True).view_as(pred)).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "\n",
    "test_dataset = PyDataset(torch.tensor(test_features).float().cuda(), torch.tensor(test_labels).float().cuda())\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "eval_NN(classifier, test_data_loader, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results of the model\n",
    "predictions = []\n",
    "for batch in test_data_loader:\n",
    "    data_input, labels = batch\n",
    "    output = classifier(data_input.float())\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    predictions.append(predicted)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the model\n",
    "class Classifier(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(Classifier, self).__init__()\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = torch.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = Classifier(19, 32, 4)\n",
    "model.train()\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(400):\n",
    "  # Forward pass\n",
    "  output = model(torch.tensor(X_resampled).float())\n",
    "  loss = loss_fn(output, torch.tensor(y_resampled).float())\n",
    "\n",
    "  # Backward pass and optimization\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: tensor(0.2268)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Calculate the accuracy on the test dataset\n",
    "with torch.no_grad():\n",
    "  output = model(torch.tensor(X_resampled).float())\n",
    "  predictions = output.argmax(dim=1)\n",
    "  accuracy = (predictions == torch.tensor(y_resampled).float().argmax(dim=1)).float().mean()\n",
    "  print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: tensor(0.4610)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Calculate the accuracy on the test dataset\n",
    "with torch.no_grad():\n",
    "  output = model(torch.tensor(features).float())\n",
    "  predictions = output.argmax(dim=1)\n",
    "  accuracy = (predictions == torch.tensor(labels).float().argmax(dim=1)).float().mean()\n",
    "  print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0821917808219178"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.argmax(test_features, axis=1) == 0).sum() / len(test_features)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>caption</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "      <td>saint nicholas festival market, place de notre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "      <td>[mobilization at perolles in august 1914]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "      <td>additional service for women, barracks de la p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>women walking down a street.</td>\n",
       "      <td>procession on the route to the alps during a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>a photograph of a large tropical cyclone.</td>\n",
       "      <td>tornado over lake morat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  label                                            caption  \\\n",
       "0    0      0                people buying sweets at the market.   \n",
       "1    1      0  a group of soldiers stand in front of a building.   \n",
       "2    2      0     soldiers stand in front of a military vehicle.   \n",
       "3    3      0                       women walking down a street.   \n",
       "4    4      0          a photograph of a large tropical cyclone.   \n",
       "\n",
       "                                               title  \n",
       "0  saint nicholas festival market, place de notre...  \n",
       "1          [mobilization at perolles in august 1914]  \n",
       "2  additional service for women, barracks de la p...  \n",
       "3  procession on the route to the alps during a w...  \n",
       "4                            tornado over lake morat  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "import torch\n",
    "df_temp = pd.DataFrame(columns=['label', 'caption', 'title'])\n",
    "df_temp['caption'] = df.caption_raw.str.lower()\n",
    "df_temp['title'] = df.title_raw.str.lower()\n",
    "df_temp['label'] = df.caption == df.title_raw\n",
    "df_temp['label'] = df_temp.label.astype(int)\n",
    "# df_temp['label'] = df_temp.label.apply(lambda x: torch.tensor([1,0]) if x==0 else torch.tensor([0,1]))\n",
    "df_temp['title'] = df_temp['title'].astype(str)\n",
    "df_temp['caption'] = df_temp['caption'].astype(str)\n",
    "df_temp = df_temp.reset_index().rename({'index':'idx'}, axis=1)\n",
    "df_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap caption and title for 50% of the data, switch label for them\n",
    "df_temp2 = df_temp.copy()\n",
    "df_temp2['caption'] = df_temp['title']\n",
    "df_temp2['title'] = df_temp['caption']\n",
    "df_temp2['label'] = df_temp2['label'].apply(lambda x: 1-x)\n",
    "df_temp2.head()\n",
    "\n",
    "df_temp = pd.concat([df_temp, df_temp2])\n",
    "df_temp = df_temp.reset_index().rename({'index':'idx'}, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "      <th>caption</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "      <td>saint nicholas festival market, place de notre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "      <td>[mobilization at perolles in august 1914]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "      <td>additional service for women, barracks de la p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>women walking down a street.</td>\n",
       "      <td>procession on the route to the alps during a w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>a photograph of a large tropical cyclone.</td>\n",
       "      <td>tornado over lake morat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>1455</td>\n",
       "      <td>1455</td>\n",
       "      <td>1</td>\n",
       "      <td>celebration of the fte-dieu, the rest of the ...</td>\n",
       "      <td>monarch and noble person celebrate the wedding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>1</td>\n",
       "      <td>cortge de la saint-nicolas, torchbearers, fri...</td>\n",
       "      <td>a group of men lighting a fire in the dark.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>1457</td>\n",
       "      <td>1457</td>\n",
       "      <td>0</td>\n",
       "      <td>woman in a boat on lake morat</td>\n",
       "      <td>portrait of a young woman.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>1458</td>\n",
       "      <td>1458</td>\n",
       "      <td>1</td>\n",
       "      <td>waves breaking on the jetty and rowing boat, l...</td>\n",
       "      <td>fishing boat on the beach.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>1459</td>\n",
       "      <td>1459</td>\n",
       "      <td>1</td>\n",
       "      <td>dissection course at the institute of anatomy ...</td>\n",
       "      <td>a medical team working in a hospital.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2920 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       idx   idx  label                                            caption  \\\n",
       "0        0     0      0                people buying sweets at the market.   \n",
       "1        1     1      0  a group of soldiers stand in front of a building.   \n",
       "2        2     2      0     soldiers stand in front of a military vehicle.   \n",
       "3        3     3      0                       women walking down a street.   \n",
       "4        4     4      0          a photograph of a large tropical cyclone.   \n",
       "...    ...   ...    ...                                                ...   \n",
       "2915  1455  1455      1  celebration of the fte-dieu, the rest of the ...   \n",
       "2916  1456  1456      1  cortge de la saint-nicolas, torchbearers, fri...   \n",
       "2917  1457  1457      0                      woman in a boat on lake morat   \n",
       "2918  1458  1458      1  waves breaking on the jetty and rowing boat, l...   \n",
       "2919  1459  1459      1  dissection course at the institute of anatomy ...   \n",
       "\n",
       "                                                  title  \n",
       "0     saint nicholas festival market, place de notre...  \n",
       "1             [mobilization at perolles in august 1914]  \n",
       "2     additional service for women, barracks de la p...  \n",
       "3     procession on the route to the alps during a w...  \n",
       "4                               tornado over lake morat  \n",
       "...                                                 ...  \n",
       "2915  monarch and noble person celebrate the wedding...  \n",
       "2916        a group of men lighting a fire in the dark.  \n",
       "2917                         portrait of a young woman.  \n",
       "2918                         fishing boat on the beach.  \n",
       "2919              a medical team working in a hospital.  \n",
       "\n",
       "[2920 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4730/3916108700.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(temp_train_df)\n",
      "/tmp/ipykernel_4730/3916108700.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  train_df = train_df.append(temp_train_df)\n",
      "/tmp/ipykernel_4730/3916108700.py:10: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  train_df = train_df.append(temp_train_df)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selected</th>\n",
       "      <th>expression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>people buying sweets at the market.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>a group of soldiers stand in front of a building.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>soldiers stand in front of a military vehicle.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>women walking down a street.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>a photograph of a large tropical cyclone.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  selected                                         expression\n",
       "0     True                people buying sweets at the market.\n",
       "1     True  a group of soldiers stand in front of a building.\n",
       "2     True     soldiers stand in front of a military vehicle.\n",
       "3     True                       women walking down a street.\n",
       "4     True          a photograph of a large tropical cyclone."
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=['selected', 'expression'])\n",
    "temp_train_df = pd.DataFrame(columns=['selected', 'expression'])\n",
    "temp_train_df['expression'] = df['caption_raw']\n",
    "temp_train_df['selected'] = df['caption'] == df['caption_raw']\n",
    "train_df = train_df.append(temp_train_df)\n",
    "\n",
    "temp_train_df = pd.DataFrame(columns=['selected', 'expression'])\n",
    "temp_train_df['expression'] = df['title_raw']\n",
    "temp_train_df['selected'] = df['caption'] == df['title_raw']\n",
    "train_df = train_df.append(temp_train_df)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_df, open('train_df.pkl', 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info from GLIP MDETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dist(df, ax, columns, feature, model_names, log_scale, discrete=False):\n",
    "    temp_df = pd.DataFrame(columns=[feature, 'model'])\n",
    "    for name, column in zip(model_names, columns):\n",
    "        for column_ in column:\n",
    "            temp_df = temp_df.append(pd.DataFrame({feature: df[column_], 'model': name}))\n",
    "    temp_df.dropna(inplace=True)\n",
    "\n",
    "    temp_df.index = range(len(temp_df))\n",
    "    # distribution of the feature for each model in percentage\n",
    "    return sns.histplot(temp_df, ax=ax, x=feature, hue='model', fill=True, common_norm=False, stat='percent', log_scale=log_scale, discrete=discrete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [['median_bbox_area_GLIP_caption', 'median_bbox_area_GLIP_title'], ['median_bbox_area_MDETR_caption', 'median_bbox_area_MDETR_title']]\n",
    "model_names = ['GLIP', 'MDETR']\n",
    "fig, ax = plt.subplots(1,2, figsize=(12, 5))\n",
    "show_dist(df, ax[1], columns, 'median_bbox_area', model_names, log_scale=True)\n",
    "ax[1].set_ylabel('Percentage')\n",
    "ax[1].set_xlabel('Median Bounding Box Area')\n",
    "ax[1].set_title('Distribution of Median Bounding Box Area')\n",
    "\n",
    "\n",
    "# do the same as above but for num_bbox\n",
    "columns = [['num_bbox_GLIP_caption', 'num_bbox_GLIP_title'], ['num_bbox_MDETR_caption', 'num_bbox_MDETR_title']]\n",
    "model_names = ['GLIP', 'MDETR']\n",
    "filterd_df = df.copy()\n",
    "for column in columns:\n",
    "    for column_ in column:\n",
    "        filterd_df = filterd_df.loc[(filterd_df[column_] < 15) & (filterd_df[column_] > 0)]\n",
    "\n",
    "show_dist(filterd_df,ax[0], columns, 'num_bbox', model_names, log_scale=False, discrete=True)\n",
    "ax[0].set_xlabel('Number of Bounding Boxes')\n",
    "ax[0].set_ylabel('Percentage')\n",
    "ax[0].set_title('Distribution of Number of Bounding Boxes')\n",
    "\n",
    "plt.savefig('../docs/assets/num_bbox_median_bbox_area.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# show_dist_plotly(df, columns, 'median_bbox_area', model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.num_bbox_GLIP_caption > 20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.index = np.arange(len(temp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(temp_df, x=\"mean_area\", hue=\"model\", kind=\"kde\", fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.loc[temp_df['mean_area'] < 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Oct 24 2022, 16:07:47) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd12328ba0a93ae9455e01a30dc1564af4ba300f8e0c01c6941d8bcfcdf1d801"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
